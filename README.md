# ğŸ•¸ï¸ Web Scraping Project (Requests, BeautifulSoup, Selenium, Web Scraper Extension)

This project is a comprehensive showcase of different web scraping techniques using:

- ğŸ **Requests + BeautifulSoup** â€” for fast scraping of static websites  
- ğŸ§ª **Selenium WebDriver** â€” for scraping dynamic, JavaScript-rendered content  
- ğŸŒ **Web Scraper Browser Extension** â€” a no-code/low-code scraping solution for structured data

---

## ğŸ“¦ What's Inside (`Data_Scrapping.zip`)

Once you extract the ZIP file, youâ€™ll find:

```
Data_Scrapping/
â”œâ”€â”€ bs4_scraper.ipynb               # Requests + BeautifulSoup example
â”œâ”€â”€ selenium_scraper.ipynb         # Selenium notebook
â”œâ”€â”€ web scrapper(website).ipynb    # Selenium + extension usage
â”œâ”€â”€ output_data.csv                # Optional sample output
â”œâ”€â”€ README.md                      # You're reading it!
â””â”€â”€ LICENSE                        # MIT license
```

---

## ğŸ§ª Method 1: Scraping with `requests` + `BeautifulSoup`

**Best for:** Static websites with HTML-rendered content only.

### ğŸ”§ Requirements

```bash
pip install requests beautifulsoup4 pandas
```

### ğŸ” Example Code Flow

```python
import requests
from bs4 import BeautifulSoup

url = 'https://example.com/products'
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')
titles = [tag.text.strip() for tag in soup.select('div.product-title')]
print(titles)
```

**âœ… Advantages**
- Simple, fast, and lightweight
- Great for HTML-rendered pages
- Easy CSV export with pandas

**âš ï¸ Limitations**
- Doesnâ€™t work with JavaScript content
- Less flexible for complex interactions

---

## ğŸ§ª Method 2: Scraping with Selenium

**Best for:** Dynamic websites with interactive content (e.g., Flipkart, Amazon)

### ğŸ”§ Requirements

- Google Chrome + ChromeDriver

```bash
pip install selenium pandas
```

### ğŸš€ Example Code Flow

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

driver = webdriver.Chrome()
driver.get("https://www.flipkart.com")

search_box = driver.find_element(By.NAME, "q")
search_box.send_keys("tripod")
search_box.send_keys(Keys.ENTER)

titles = driver.find_elements(By.CLASS_NAME, "s1Q9rs")
for title in titles:
    print(title.text)
```

**âœ… Features**
- Simulates real user actions
- Works great with JavaScript-heavy pages

**âš ï¸ Limitations**
- Slower compared to static scraping
- Requires WebDriver setup
- May be blocked by anti-bot tools

---

## ğŸŒ Method 3: Web Scraper Browser Extension

**Best for:** Beginners or no-code users scraping structured content

### ğŸ§© Installation

- Chrome: [Web Scraper Extension](https://chrome.google.com/webstore/detail/web-scraper/)
- Firefox: Search for it in the Add-ons store

### ğŸªœ Steps to Use

1. Open target website
2. Click the Web Scraper icon â†’ Open Sitemap Editor
3. Create sitemap & define selectors
4. Start scraping & export to CSV/JSON

**âœ… Features**
- No programming needed
- Works within browser
- Ideal for structured lists & tables

**âš ï¸ Limitations**
- May struggle with large datasets
- Limited by what the browser can load

---

## ğŸ“Œ Tool Comparison

| Tool              | Best For                             | Handles JavaScript? |
|-------------------|--------------------------------------|---------------------|
| `requests + bs4`  | Fast, simple static scraping         | âŒ No               |
| `Selenium`        | Dynamic content & user interaction   | âœ… Yes              |
| `Web Scraper Ext` | Visual scraping for structured data  | âœ… Yes              |

---

## âœ… License

This project is licensed under the MIT License â€“ see the `LICENSE` file for details.

---

## âœï¸ Author

**Abhinava Ghosh**  
ğŸ“§ Email: `susmitasurcoc600@gmail.com`

---

## ğŸ¤ Contributions

Feel free to fork this repo or open issues/PRs to improve it.

---

## â­ Star This Project

If you found this helpful, don't forget to â­ it on GitHub!
```
